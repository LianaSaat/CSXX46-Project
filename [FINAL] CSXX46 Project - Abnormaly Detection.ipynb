{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ci-X2fp7iUJn",
    "outputId": "795f5c53-51f5-46d0-b476-64baaaaaac6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dataset size: 3250 rows\n",
      "Episode 1/100, Steps 99\n",
      "Episode 2/100, Steps 99\n",
      "Episode 3/100, Steps 99\n",
      "Episode 4/100, Steps 99\n",
      "Episode 5/100, Steps 99\n",
      "Episode 6/100, Steps 99\n",
      "Episode 7/100, Steps 99\n",
      "Episode 8/100, Steps 99\n",
      "Episode 9/100, Steps 99\n",
      "Episode 10/100, Steps 99\n",
      "Episode 11/100, Steps 99\n",
      "Episode 12/100, Steps 99\n",
      "Episode 13/100, Steps 99\n",
      "Episode 14/100, Steps 99\n",
      "Episode 15/100, Steps 99\n",
      "Episode 16/100, Steps 99\n",
      "Episode 17/100, Steps 99\n",
      "Episode 18/100, Steps 99\n",
      "Episode 19/100, Steps 99\n",
      "Episode 20/100, Steps 99\n",
      "Episode 21/100, Steps 99\n",
      "Episode 22/100, Steps 99\n",
      "Episode 23/100, Steps 99\n",
      "Episode 24/100, Steps 99\n",
      "Episode 25/100, Steps 99\n",
      "Episode 26/100, Steps 99\n",
      "Episode 27/100, Steps 99\n",
      "Episode 28/100, Steps 99\n",
      "Episode 29/100, Steps 99\n",
      "Episode 30/100, Steps 99\n",
      "Episode 31/100, Steps 99\n",
      "Episode 32/100, Steps 99\n",
      "Episode 33/100, Steps 99\n",
      "Episode 34/100, Steps 99\n",
      "Episode 35/100, Steps 99\n",
      "Episode 36/100, Steps 99\n",
      "Episode 37/100, Steps 99\n",
      "Episode 38/100, Steps 99\n",
      "Episode 39/100, Steps 99\n",
      "Episode 40/100, Steps 99\n",
      "Episode 41/100, Steps 99\n",
      "Episode 42/100, Steps 99\n",
      "Episode 43/100, Steps 99\n",
      "Episode 44/100, Steps 99\n",
      "Episode 45/100, Steps 99\n",
      "Episode 46/100, Steps 99\n",
      "Episode 47/100, Steps 99\n",
      "Episode 48/100, Steps 99\n",
      "Episode 49/100, Steps 99\n",
      "Episode 50/100, Steps 99\n",
      "Episode 51/100, Steps 99\n",
      "Episode 52/100, Steps 99\n",
      "Episode 53/100, Steps 99\n",
      "Episode 54/100, Steps 99\n",
      "Episode 55/100, Steps 99\n",
      "Episode 56/100, Steps 99\n",
      "Episode 57/100, Steps 99\n",
      "Episode 58/100, Steps 99\n",
      "Episode 59/100, Steps 99\n",
      "Episode 60/100, Steps 99\n",
      "Episode 61/100, Steps 99\n",
      "Episode 62/100, Steps 99\n",
      "Episode 63/100, Steps 99\n",
      "Episode 64/100, Steps 99\n",
      "Episode 65/100, Steps 99\n",
      "Episode 66/100, Steps 99\n",
      "Episode 67/100, Steps 99\n",
      "Episode 68/100, Steps 99\n",
      "Episode 69/100, Steps 99\n",
      "Episode 70/100, Steps 99\n",
      "Episode 71/100, Steps 99\n",
      "Episode 72/100, Steps 99\n",
      "Episode 73/100, Steps 99\n",
      "Episode 74/100, Steps 99\n",
      "Episode 75/100, Steps 99\n",
      "Episode 76/100, Steps 99\n",
      "Episode 77/100, Steps 99\n",
      "Episode 78/100, Steps 99\n",
      "Episode 79/100, Steps 99\n",
      "Episode 80/100, Steps 99\n",
      "Episode 81/100, Steps 99\n",
      "Episode 82/100, Steps 99\n",
      "Episode 83/100, Steps 99\n",
      "Episode 84/100, Steps 99\n",
      "Episode 85/100, Steps 99\n",
      "Episode 86/100, Steps 99\n",
      "Episode 87/100, Steps 99\n",
      "Episode 88/100, Steps 99\n",
      "Episode 89/100, Steps 99\n",
      "Episode 90/100, Steps 99\n",
      "Episode 91/100, Steps 99\n",
      "Episode 92/100, Steps 99\n",
      "Episode 93/100, Steps 99\n",
      "Episode 94/100, Steps 99\n",
      "Episode 95/100, Steps 99\n",
      "Episode 96/100, Steps 99\n",
      "Episode 97/100, Steps 99\n",
      "Episode 98/100, Steps 99\n",
      "Episode 99/100, Steps 99\n",
      "Episode 100/100, Steps 99\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.71      0.82       637\n",
      "           1       0.02      0.23      0.03        13\n",
      "\n",
      "    accuracy                           0.70       650\n",
      "   macro avg       0.50      0.47      0.42       650\n",
      "weighted avg       0.96      0.70      0.80       650\n",
      "\n",
      "\n",
      "Confusion Matrix Results:\n",
      "True Positives (TP): 3\n",
      "True Negatives (TN): 450\n",
      "False Positives (FP): 187\n",
      "False Negatives (FN): 10\n",
      "\n",
      "Accuracy (ACC): 0.70\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import skfuzzy as fuzz\n",
    "import skfuzzy.control as ctrl\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "# Load cleaned dataset\n",
    "data = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "data_sampled, _ = train_test_split(data, test_size=0.998, stratify=data['anomaly'], random_state=42)\n",
    "print(f\"Reduced dataset size: {data_sampled.shape[0]} rows\")\n",
    "\n",
    "X = data_sampled[['meter_reading']].values\n",
    "y = data_sampled['anomaly'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "meter_reading = ctrl.Antecedent(np.arange(0, 1.01, 0.01), 'meter_reading')\n",
    "anomaly = ctrl.Antecedent(np.arange(0, 2, 1), 'anomaly')\n",
    "reward = ctrl.Consequent(np.arange(-1, 2, 0.1), 'reward')\n",
    "\n",
    "meter_reading['low'] = fuzz.trapmf(meter_reading.universe, [0, 0, 0.25, 0.5])\n",
    "meter_reading['medium'] = fuzz.trimf(meter_reading.universe, [0.25, 0.5, 0.75])\n",
    "meter_reading['high'] = fuzz.trapmf(meter_reading.universe, [0.5, 0.75, 1.0, 1.0])\n",
    "\n",
    "# Membership functions for anomaly\n",
    "anomaly['normal'] = fuzz.trimf(anomaly.universe, [0, 0, 1])\n",
    "anomaly['abnormal'] = fuzz.trimf(anomaly.universe, [0, 1, 1])\n",
    "\n",
    "reward['negative'] = fuzz.trapmf(reward.universe, [-1, -1, -0.5, 0])\n",
    "reward['neutral'] = fuzz.trimf(reward.universe, [-0.5, 0, 0.5])\n",
    "reward['positive'] = fuzz.trapmf(reward.universe, [0, 0.5, 1, 1])\n",
    "\n",
    "rule1 = ctrl.Rule(meter_reading['low'] & anomaly['normal'], reward['positive'])\n",
    "rule2 = ctrl.Rule(meter_reading['medium'] & anomaly['abnormal'], reward['negative'])\n",
    "rule3 = ctrl.Rule(meter_reading['high'], reward['neutral'])\n",
    "\n",
    "reward_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])\n",
    "reward_system = ctrl.ControlSystemSimulation(reward_ctrl)\n",
    "\n",
    "class AnomalyDetectionEnv:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.current_index = 0\n",
    "        self.state = self.X[self.current_index]\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_index = 0\n",
    "        indices = np.arange(len(self.X))\n",
    "        np.random.shuffle(indices)\n",
    "        self.X, self.y = self.X[indices], self.y[indices]\n",
    "        self.state = self.X[self.current_index]\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Take an action and return the next state, reward, and whether the episode is done.\n",
    "\n",
    "        Args:\n",
    "            action (int): The predicted label (0: normal, 1: abnormal).\n",
    "\n",
    "        Returns:\n",
    "            next_state (np.array): The next state.\n",
    "            reward (int): Reward (1 for correct classification, 0 for incorrect classification).\n",
    "            done (bool): Whether the episode has ended.\n",
    "        \"\"\"\n",
    "        # Calculate the reward\n",
    "        correct_label = self.y[self.current_index]\n",
    "        reward = 1 if action == correct_label else 0\n",
    "\n",
    "        self.current_index += 1\n",
    "        done = self.current_index >= len(self.X) or self.current_index >= 100  # Limit episode length\n",
    "\n",
    "        if not done:\n",
    "            self.state = self.X[self.current_index]\n",
    "        else:\n",
    "            self.state = None  \n",
    "\n",
    "        return self.state, reward, done\n",
    "\n",
    "class DRLAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.main_model = self._build_model()  # Main network\n",
    "        self.target_model = self._build_model()  # Target network\n",
    "        self.update_target_network()\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.learning_rate = 0.001\n",
    "        self.update_target_freq = 5  # Frequency to update target network\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(self.state_size,)),\n",
    "            layers.Dense(24, activation='relu'),\n",
    "            layers.Dense(24, activation='relu'),\n",
    "            layers.Dense(self.action_size, activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "        return model\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_model.set_weights(self.main_model.get_weights())\n",
    "\n",
    "    def fuzzy_predict_action(self, state):\n",
    "        \"\"\"\n",
    "        Predict action using the fuzzy logic system based on the current state.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            reward_system.input['meter_reading'] = state[0]\n",
    "            reward_system.input['anomaly'] = 0  \n",
    "            reward_system.compute()\n",
    "            fuzzy_reward = reward_system.output['reward']\n",
    "\n",
    "            return 1 if fuzzy_reward > 0 else 0\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError in fuzzy system: {e}\")\n",
    "            return 0  # Default action in case of error\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        q_values = self.main_model.predict(state, verbose=0)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                # Use fuzzy logic to predict the next action\n",
    "                predicted_action = self.fuzzy_predict_action(next_state[0])\n",
    "                q_next = self.target_model.predict(next_state, verbose=0)[0][predicted_action]\n",
    "                target += self.gamma * q_next\n",
    "            target_f = self.main_model.predict(state, verbose=0)\n",
    "            target_f[0][action] = target\n",
    "            self.main_model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def train(self, episodes, batch_size, env):\n",
    "        for e in range(episodes):\n",
    "            state = env.reset()\n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "\n",
    "            for time in range(100):  # Limit steps per episode\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done = env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, self.state_size])\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                if done:\n",
    "                    print(f\"Episode {e+1}/{episodes}, Steps {time}\")\n",
    "                    break\n",
    "            self.replay(batch_size)\n",
    "\n",
    "            # Update the target network periodically using fuzzy predictions\n",
    "            if e % self.update_target_freq == 0:\n",
    "                self.update_target_network()\n",
    "\n",
    "env = AnomalyDetectionEnv(X_train, y_train)\n",
    "agent = DRLAgent(state_size=X_train.shape[1], action_size=2)\n",
    "\n",
    "episodes = 100\n",
    "batch_size = 32\n",
    "agent.train(episodes, batch_size, env)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = []\n",
    "for i in range(len(X_test)):\n",
    "    state = np.reshape(X_test[i], [1, agent.state_size])\n",
    "    action = agent.act(state)\n",
    "    y_pred.append(action)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute accuracy manually using the confusion matrix\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return acc, tp, tn, fp, fn\n",
    "\n",
    "accuracy, tp, tn, fp, fn = calculate_accuracy(y_test, y_pred)\n",
    "\n",
    "print(\"\\nConfusion Matrix Results:\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "print(f\"\\nAccuracy (ACC): {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLlU6wHpB_iY",
    "outputId": "483955f8-3978-4a7f-86ca-8c33cd52bdb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       637\n",
      "           1       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.98       650\n",
      "   macro avg       0.49      0.50      0.49       650\n",
      "weighted avg       0.96      0.98      0.97       650\n",
      "\n",
      "\n",
      "Confusion Matrix Results:\n",
      "True Positives (TP): 0\n",
      "True Negatives (TN): 637\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 13\n",
      "\n",
      "Accuracy (ACC): 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train an SVM model\n",
    "svm_model = SVC(kernel='rbf', gamma='scale', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "accuracy, tp, tn, fp, fn = calculate_accuracy(y_test, y_pred_svm)\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix Results:\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "print(f\"\\nAccuracy (ACC): {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMMIxzhjzxY0",
    "outputId": "d6a679ff-1d05-461f-db25-0ae336a80d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.3419 - val_accuracy: 0.9803 - val_loss: 0.0981\n",
      "Epoch 2/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.1041 - val_accuracy: 0.9803 - val_loss: 0.0975\n",
      "Epoch 3/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.1042 - val_accuracy: 0.9803 - val_loss: 0.0986\n",
      "Epoch 4/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.1014 - val_accuracy: 0.9803 - val_loss: 0.0980\n",
      "Epoch 5/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.1162 - val_accuracy: 0.9803 - val_loss: 0.0976\n",
      "Epoch 6/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.1145 - val_accuracy: 0.9803 - val_loss: 0.0982\n",
      "Epoch 7/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.1051 - val_accuracy: 0.9803 - val_loss: 0.0970\n",
      "Epoch 8/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9764 - loss: 0.1100 - val_accuracy: 0.9803 - val_loss: 0.0968\n",
      "Epoch 9/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.1068 - val_accuracy: 0.9803 - val_loss: 0.0966\n",
      "Epoch 10/10\n",
      "\u001b[1m407/407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.1087 - val_accuracy: 0.9803 - val_loss: 0.0970\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3187\n",
      "           1       0.00      0.00      0.00        64\n",
      "\n",
      "    accuracy                           0.98      3251\n",
      "   macro avg       0.49      0.50      0.50      3251\n",
      "weighted avg       0.96      0.98      0.97      3251\n",
      "\n",
      "\n",
      "Confusion Matrix Results:\n",
      "True Positives (TP): 0\n",
      "True Negatives (TN): 3187\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 64\n",
      "\n",
      "Accuracy (ACC): 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "X_train_cnn = X_train.reshape(-1, X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(-1, X_test.shape[1], 1)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv1D(32, 1, activation='relu', input_shape=(X_train.shape[1], 1)),  # Kernel size = 1\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
    "\n",
    "y_pred_cnn = (cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cnn))\n",
    "\n",
    "accuracy, tp, tn, fp, fn = calculate_accuracy(y_test, y_pred_cnn)\n",
    "\n",
    "print(\"\\nConfusion Matrix Results:\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "print(f\"\\nAccuracy (ACC): {accuracy:.2f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
